[config]
path_train = ../train_debate_wordnet+concept.txt 
path_dev = ../dev_debate_wordnet+concept.txt 
path_test = ../test_debate_wordnet+concept.txt
default_label = O
model_selector = dev_tok__f:high
preload_vectors = ../glove.6B.300d.txt
word_embedding_size = 300
emb_initial_zero = False
train_embeddings = True
word_recurrent_size = 300
lmcost_max_vocab_size = 7500
lmcost_hidden_layer_size = 50
lmcost_lstm_gamma = 0.0
lmcost_joint_lstm_gamma = 0.0
lmcost_char_gamma = 0.0
lmcost_joint_char_gamma = 0.0
hidden_layer_size = 100
lowercase = True
replace_digits = True
min_word_freq = -1
allowed_word_length = -1
max_train_sent_length = -1
vocab_include_devtest = True
vocab_only_embedded = False
initializer = glorot
opt_strategy = adam
learningrate = 0.001
elmo = False
clip = 5.0
batch_equal_size = False
max_batch_size = 64
epochs = 30
stop_if_no_improvement_for_epochs = 10
learningrate_decay = 0.9
dropout_input = 0.001
dropout_word_lstm = 0.001
tf_per_process_gpu_memory_fraction = 1.0
tf_allow_growth = True
output_path = ./result_know/
knowledge_add = True
gate = False
save = ./model/model_debate_know
load = ./model/model_essay_know
garbage_collection = False
lstm_use_peepholes = True
whidden_layer_size = 200
attention_evidence_size = 300
attention_activation = soft
attention_objective_weight = 0.01
sentence_objective_weight = 1.0
sentence_objective_persistent = True
word_objective_weight = 0.0
sentence_composition = attention
random_seed = 12323
neural_network = BILSTM
human_needs = reiss
